"""
Chapter 13: Evaluators - L2 & L3: LLM-as-Judge

LLMì„ ì‚¬ìš©í•˜ì—¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ(L2)ê³¼ ê·¼ê±° ì¶©ë¶„ì„±(L3)ì„ í‰ê°€í•©ë‹ˆë‹¤.
"""

import json
import os

from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel, Field

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ============================================================
# ë°ì´í„° ëª¨ë¸
# ============================================================


class JudgeScore(BaseModel):
    """LLM Judge í‰ê°€ ê²°ê³¼"""

    score: int = Field(ge=1, le=5, description="1-5ì ")
    reasoning: str = Field(description="í‰ê°€ ê·¼ê±°")


# ============================================================
# L2: ì²´í¬ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
# ============================================================


class ChecklistJudge:
    """
    L2: ì²´í¬ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€ (LLM-as-Judge)

    í‰ê°€ ê¸°ì¤€:
    1. êµ¬ì²´ì„±: ê²€ì¦ í¬ì¸íŠ¸ê°€ êµ¬ì²´ì ì´ê³  ëª…í™•í•œê°€?
    2. í¬ê´„ì„±: ì£¼ì¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ì£¼ìš” ì¸¡ë©´ì„ ëª¨ë‘ ë‹¤ë£¨ëŠ”ê°€?
    3. ê²€ì¦ê°€ëŠ¥ì„±: ê° í¬ì¸íŠ¸ê°€ ì‹¤ì œë¡œ ê²€ì¦ ê°€ëŠ¥í•œê°€?
    4. ê´€ë ¨ì„±: ëª¨ë“  í¬ì¸íŠ¸ê°€ ì£¼ì¥ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ìˆëŠ”ê°€?
    """

    MODEL = "gpt-5.1"

    PROMPT = """ë‹¹ì‹ ì€ íŒ©íŠ¸ì²´í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[í‰ê°€ ê¸°ì¤€]
1. êµ¬ì²´ì„±: ê²€ì¦ í¬ì¸íŠ¸ê°€ êµ¬ì²´ì ì´ê³  ëª…í™•í•œê°€?
2. í¬ê´„ì„±: ì£¼ì¥ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ì£¼ìš” ì¸¡ë©´ì„ ëª¨ë‘ ë‹¤ë£¨ëŠ”ê°€?
3. ê²€ì¦ê°€ëŠ¥ì„±: ê° í¬ì¸íŠ¸ê°€ ì‹¤ì œë¡œ ê²€ì¦ ê°€ëŠ¥í•œê°€?
4. ê´€ë ¨ì„±: ëª¨ë“  í¬ì¸íŠ¸ê°€ ì£¼ì¥ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ìˆëŠ”ê°€?

[ì…ë ¥]
- ê²€ì¦í•  ì£¼ì¥: {claim}
- ìƒì„±ëœ ì²´í¬ë¦¬ìŠ¤íŠ¸:
{checklist}

[ì ìˆ˜ ê¸°ì¤€]
- 5: ë§¤ìš° ìš°ìˆ˜ (ëª¨ë“  ê¸°ì¤€ ì¶©ì¡±, ì „ë¬¸ê°€ ìˆ˜ì¤€)
- 4: ìš°ìˆ˜ (ëŒ€ë¶€ë¶„ ê¸°ì¤€ ì¶©ì¡±, ì•½ê°„ì˜ ê°œì„  ì—¬ì§€)
- 3: ë³´í†µ (ì¼ë¶€ ê°œì„  í•„ìš”, ê¸°ë³¸ì ì¸ ìˆ˜ì¤€)
- 2: ë¯¸í¡ (ìƒë‹¹í•œ ê°œì„  í•„ìš”, í•µì‹¬ ëˆ„ë½)
- 1: ë§¤ìš° ë¯¸í¡ (ì „ë©´ ì¬ì‘ì„± í•„ìš”)

[ì¶œë ¥ í˜•ì‹]
JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
{{"score": 1-5, "reasoning": "í‰ê°€ ê·¼ê±°"}}
"""

    def __init__(self):
        self.client = client

    def evaluate(self, claim: str, checklist: list) -> JudgeScore:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€"""
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ í¬ë§·íŒ…
        checklist_text = ""
        for item in checklist:
            if hasattr(item, "point"):
                point = item.point
                source_type = getattr(item, "source_type", "")
                if source_type:
                    checklist_text += f"- {point} (ì¶œì²˜ ìœ í˜•: {source_type})\n"
                else:
                    checklist_text += f"- {point}\n"
            else:
                checklist_text += f"- {item}\n"

        prompt = self.PROMPT.format(claim=claim, checklist=checklist_text)

        response = self.client.responses.create(
            model=self.MODEL,
            instructions=prompt,
            input=[
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": "ìœ„ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."}
                    ],
                }
            ],
            text={"format": {"type": "json_object"}},
        )

        data = json.loads(response.output_text)
        return JudgeScore(**data)


# ============================================================
# L3: ê·¼ê±° ì¶©ë¶„ì„± í‰ê°€
# ============================================================


class EvidenceJudge:
    """
    L3: ê·¼ê±° ì¶©ë¶„ì„± í‰ê°€ (LLM-as-Judge)

    í‰ê°€ ê¸°ì¤€:
    1. ì¶©ë¶„ì„±: ê²°ë¡ ì„ ë’·ë°›ì¹¨í•˜ê¸°ì— ì¶©ë¶„í•œ ê·¼ê±°ì¸ê°€?
    2. ì‹ ë¢°ì„±: ê·¼ê±°ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ì—ì„œ ì™”ëŠ”ê°€?
    3. ë…¼ë¦¬ì„±: ê·¼ê±°ì—ì„œ ê²°ë¡ ìœ¼ë¡œì˜ ë…¼ë¦¬ì  ì—°ê²°ì´ íƒ€ë‹¹í•œê°€?
    4. ëª…í™•ì„±: ê·¼ê±°ê°€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
    """

    MODEL = "gpt-5.1"

    PROMPT = """ë‹¹ì‹ ì€ íŒ©íŠ¸ì²´í¬ ê·¼ê±° í’ˆì§ˆ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[í‰ê°€ ê¸°ì¤€]
1. ì¶©ë¶„ì„±: ê²°ë¡ ì„ ë’·ë°›ì¹¨í•˜ê¸°ì— ì¶©ë¶„í•œ ê·¼ê±°ì¸ê°€?
2. ì‹ ë¢°ì„±: ê·¼ê±°ê°€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ì—ì„œ ì™”ëŠ”ê°€?
3. ë…¼ë¦¬ì„±: ê·¼ê±°ì—ì„œ ê²°ë¡ ìœ¼ë¡œì˜ ë…¼ë¦¬ì  ì—°ê²°ì´ íƒ€ë‹¹í•œê°€?
4. ëª…í™•ì„±: ê·¼ê±°ê°€ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?

[ì…ë ¥]
- ê²€ì¦í•  ì£¼ì¥: {claim}
- íŒì •: {verdict}
- ì‹ ë¢°ë„: {confidence}
- ì œì‹œëœ ê·¼ê±°: {evidence}
- ì²´í¬ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ê²°ê³¼:
{checklist_results}

[ì ìˆ˜ ê¸°ì¤€]
- 5: ë§¤ìš° ìš°ìˆ˜ (ì¶©ë¶„í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê·¼ê±°, ë…¼ë¦¬ì  ì—°ê²° ì™„ë²½)
- 4: ìš°ìˆ˜ (ëŒ€ì²´ë¡œ ì¶©ë¶„í•œ ê·¼ê±°, ì•½ê°„ì˜ ë³´ì™„ í•„ìš”)
- 3: ë³´í†µ (ê¸°ë³¸ì ì¸ ê·¼ê±° ì œì‹œ, ì¶”ê°€ ê²€ì¦ ê¶Œì¥)
- 2: ë¯¸í¡ (ê·¼ê±° ë¶ˆì¶©ë¶„, ì¶œì²˜ ë¶ˆëª…í™•)
- 1: ë§¤ìš° ë¯¸í¡ (ê·¼ê±° ì—†ìŒ ë˜ëŠ” ë…¼ë¦¬ì  ë¹„ì•½)

[ì¶œë ¥ í˜•ì‹]
JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
{{"score": 1-5, "reasoning": "í‰ê°€ ê·¼ê±°"}}
"""

    def __init__(self):
        self.client = client

    def evaluate(
        self,
        claim: str,
        verdict: str,
        confidence: float,
        evidence: str,
        checklist: list,
    ) -> JudgeScore:
        """ê·¼ê±° ì¶©ë¶„ì„± í‰ê°€"""
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ê²°ê³¼ í¬ë§·íŒ…
        checklist_text = ""
        for item in checklist:
            if hasattr(item, "point"):
                point = item.point
                result = getattr(item, "result", "")
                checklist_text += f"- {point}\n"
                if result:
                    checklist_text += f"  â†’ {result}\n"
            else:
                checklist_text += f"- {item}\n"

        prompt = self.PROMPT.format(
            claim=claim,
            verdict=verdict,
            confidence=confidence,
            evidence=evidence,
            checklist_results=checklist_text,
        )

        response = self.client.responses.create(
            model=self.MODEL,
            instructions=prompt,
            input=[
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": "ìœ„ ê·¼ê±°ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”. JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."}
                    ],
                }
            ],
            text={"format": {"type": "json_object"}},
        )

        data = json.loads(response.output_text)
        return JudgeScore(**data)


# ============================================================
# í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰
# ============================================================

if __name__ == "__main__":
    print("LLM-as-Judge í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    claim = "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì´ë‹¤"
    checklist = [
        {"point": "ëŒ€í•œë¯¼êµ­ í—Œë²•ì—ì„œ ìˆ˜ë„ ê·œì • í™•ì¸", "source_type": "official"},
        {"point": "ì •ë¶€ ê³µì‹ ë¬¸ì„œì—ì„œ ì„œìš¸ ìˆ˜ë„ ëª…ì‹œ í™•ì¸", "source_type": "official"},
        {"point": "êµ­ì œê¸°êµ¬ì˜ ëŒ€í•œë¯¼êµ­ ìˆ˜ë„ ì •ë³´ í™•ì¸", "source_type": "database"},
    ]

    # L2: ì²´í¬ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
    print("\nğŸ“‹ L2: ì²´í¬ë¦¬ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€")
    checklist_judge = ChecklistJudge()

    class MockItem:
        def __init__(self, d):
            self.point = d["point"]
            self.source_type = d.get("source_type", "")

    mock_checklist = [MockItem(c) for c in checklist]
    result = checklist_judge.evaluate(claim, mock_checklist)
    print(f"  ì ìˆ˜: {result.score}/5")
    print(f"  ê·¼ê±°: {result.reasoning}")

    # L3: ê·¼ê±° ì¶©ë¶„ì„± í‰ê°€
    print("\nğŸ“„ L3: ê·¼ê±° ì¶©ë¶„ì„± í‰ê°€")
    evidence_judge = EvidenceJudge()
    result = evidence_judge.evaluate(
        claim=claim,
        verdict="TRUE",
        confidence=0.95,
        evidence="ëŒ€í•œë¯¼êµ­ í—Œë²• ì œ1ì¡°ì— ë”°ë¥´ë©´ ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.",
        checklist=mock_checklist,
    )
    print(f"  ì ìˆ˜: {result.score}/5")
    print(f"  ê·¼ê±°: {result.reasoning}")
